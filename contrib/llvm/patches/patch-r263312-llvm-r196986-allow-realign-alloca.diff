Pull in r196986 from upstream llvm trunk (by Reid Kleckner):

  Revert the backend fatal error from r196939

  The combination of inline asm, stack realignment, and dynamic allocas
  turns out to be too common to reject out of hand.

  ASan inserts empy inline asm fragments and uses aligned allocas.
  Compiling any trivial function containing a dynamic alloca with ASan is
  enough to trigger the check.

  XFAIL the test cases that would be miscompiled and add one that uses the
  relevant functionality.

Introduced here: http://svnweb.freebsd.org/changeset/base/263312

Index: lib/Target/X86/X86RegisterInfo.cpp
===================================================================
--- lib/Target/X86/X86RegisterInfo.cpp
+++ lib/Target/X86/X86RegisterInfo.cpp
@@ -347,12 +347,6 @@ BitVector X86RegisterInfo::getReservedRegs(const M
         "Stack realignment in presence of dynamic allocas is not supported with"
         "this calling convention.");
 
-    // FIXME: Do a proper analysis of the inline asm to see if it actually
-    // conflicts with the base register we chose.
-    if (MF.hasInlineAsm())
-      report_fatal_error("Stack realignment in presence of dynamic stack "
-                         "adjustments is not supported with inline assembly.");
-
     for (MCSubRegIterator I(getBaseRegister(), this, /*IncludeSelf=*/true);
          I.isValid(); ++I)
       Reserved.set(*I);
Index: test/CodeGen/X86/inline-asm-stack-realign3.ll
===================================================================
--- test/CodeGen/X86/inline-asm-stack-realign3.ll
+++ test/CodeGen/X86/inline-asm-stack-realign3.ll
@@ -0,0 +1,29 @@
+; RUN: llc -march=x86 < %s | FileCheck %s
+
+declare void @bar(i32* %junk)
+
+define i32 @foo(i1 %cond) {
+entry:
+  %r = alloca i32, align 128
+  store i32 -1, i32* %r, align 128
+  br i1 %cond, label %doit, label %skip
+
+doit:
+  call void asm sideeffect "xor %ecx, %ecx\0A\09mov %ecx, $0", "=*m,~{ecx},~{flags}"(i32* %r)
+  %junk = alloca i32
+  call void @bar(i32* %junk)
+  br label %skip
+
+skip:
+  %0 = load i32* %r, align 128
+  ret i32 %0
+}
+
+; CHECK-LABEL: foo:
+; CHECK: pushl %ebp
+; CHECK: andl $-128, %esp
+; CHECK: xor %ecx, %ecx
+; CHECK-NEXT: mov %ecx, (%esi)
+; CHECK: movl (%esi), %eax
+; CHECK: popl %ebp
+; CHECK: ret
Index: test/CodeGen/X86/inline-asm-stack-realign.ll
===================================================================
--- test/CodeGen/X86/inline-asm-stack-realign.ll
+++ test/CodeGen/X86/inline-asm-stack-realign.ll
@@ -1,8 +1,8 @@
 ; RUN: not llc -mtriple=i686-pc-win32 < %s 2>&1 | FileCheck %s
 
-; We don't currently support realigning the stack and adjusting the stack
-; pointer in inline asm.  This commonly happens in MS inline assembly using
-; push and pop.
+; FIXME: This is miscompiled due to our unconditional use of ESI as the base
+; pointer.
+; XFAIL:
 
 ; CHECK: Stack realignment in presence of dynamic stack adjustments is not supported with inline assembly
 
Index: test/CodeGen/X86/inline-asm-stack-realign2.ll
===================================================================
--- test/CodeGen/X86/inline-asm-stack-realign2.ll
+++ test/CodeGen/X86/inline-asm-stack-realign2.ll
@@ -1,7 +1,8 @@
 ; RUN: not llc -mtriple=i686-pc-win32 < %s 2>&1 | FileCheck %s
 
-; We don't currently support realigning the stack and adjusting the stack
-; pointer in inline asm.  This can even happen in GNU asm.
+; FIXME: This is miscompiled due to our unconditional use of ESI as the base
+; pointer.
+; XFAIL:
 
 ; CHECK: Stack realignment in presence of dynamic stack adjustments is not supported with inline assembly
 
